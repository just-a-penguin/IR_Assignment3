{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   load train_data.csv\n",
    "train_data = pd.read_csv('usb_df_train.csv')\n",
    "train_data.head()\n",
    "test_data = pd.read_csv('usb_df_test.csv')\n",
    "test_data.head()\n",
    "\n",
    "# drop NaN values\n",
    "train_data = train_data.dropna()\n",
    "test_data = test_data.dropna()\n",
    "\n",
    "X_train=train_data[\"reviewText\"]\n",
    "y_train=train_data[\"rating_class\"]\n",
    "X_test=test_data[\"reviewText\"]\n",
    "y_test=test_data[\"rating_class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "X_train_vectors = vectorizer.fit_transform(X_train)\n",
    "X_test_vectors = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAIVE BAYES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7649880095923262\n",
      "[[  0   0  54]\n",
      " [  0  19 139]\n",
      " [  0   3 619]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Average       0.00      0.00      0.00        54\n",
      "         Bad       0.86      0.12      0.21       158\n",
      "        Good       0.76      1.00      0.86       622\n",
      "\n",
      "    accuracy                           0.76       834\n",
      "   macro avg       0.54      0.37      0.36       834\n",
      "weighted avg       0.73      0.76      0.68       834\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model_nb = MultinomialNB()\n",
    "model_nb.fit(X_train_vectors, y_train)\n",
    "predictions_nb = model_nb.predict(X_test_vectors)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions_nb))\n",
    "#  give F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, predictions_nb, average='weighted')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, predictions_nb))\n",
    "\n",
    "# print F1 scores of each\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, predictions_nb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8105515587529976\n",
      "0.7666345564209157\n",
      "[[  0   8  46]\n",
      " [  0  66  92]\n",
      " [  0  12 610]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Average       0.00      0.00      0.00        54\n",
      "         Bad       0.77      0.42      0.54       158\n",
      "        Good       0.82      0.98      0.89       622\n",
      "\n",
      "    accuracy                           0.81       834\n",
      "   macro avg       0.53      0.47      0.48       834\n",
      "weighted avg       0.75      0.81      0.77       834\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_lr = LogisticRegression(max_iter=1000)\n",
    "model_lr.fit(X_train_vectors, y_train)\n",
    "predictions_lr = model_lr.predict(X_test_vectors)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions_lr))\n",
    "#  give F1 score\n",
    "print(f1_score(y_test, predictions_lr, average='weighted'))\n",
    "\n",
    "#  give confusion matrix\n",
    "print(confusion_matrix(y_test, predictions_lr))\n",
    "\n",
    "# print F1 scores of each\n",
    "print(classification_report(y_test, predictions_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUPPORT VECTOR MACHINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8009592326139089\n",
      "[[  0   3  51]\n",
      " [  0  49 109]\n",
      " [  0   3 619]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Average       0.00      0.00      0.00        54\n",
      "         Bad       0.89      0.31      0.46       158\n",
      "        Good       0.79      1.00      0.88       622\n",
      "\n",
      "    accuracy                           0.80       834\n",
      "   macro avg       0.56      0.44      0.45       834\n",
      "weighted avg       0.76      0.80      0.75       834\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model_svm = SVC()\n",
    "model_svm.fit(X_train_vectors, y_train)\n",
    "predictions_svm = model_svm.predict(X_test_vectors)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions_svm))\n",
    "\n",
    "#  give F1 score\n",
    "f1_score(y_test, predictions_svm, average='weighted')\n",
    "\n",
    "#  give confusion matrix\n",
    "print(confusion_matrix(y_test, predictions_svm))\n",
    "\n",
    "# print F1 scores of each\n",
    "print(classification_report(y_test, predictions_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7973621103117506\n",
      "[[  0   4  50]\n",
      " [  0  54 104]\n",
      " [  0  11 611]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Average       0.00      0.00      0.00        54\n",
      "         Bad       0.78      0.34      0.48       158\n",
      "        Good       0.80      0.98      0.88       622\n",
      "\n",
      "    accuracy                           0.80       834\n",
      "   macro avg       0.53      0.44      0.45       834\n",
      "weighted avg       0.74      0.80      0.75       834\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model_rf.fit(X_train_vectors, y_train)\n",
    "predictions_rf = model_rf.predict(X_test_vectors)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions_rf))\n",
    "\n",
    "#  give F1 score\n",
    "f1_score(y_test, predictions_rf, average='weighted')\n",
    "\n",
    "#  give confusion matrix\n",
    "print(confusion_matrix(y_test, predictions_rf))\n",
    "\n",
    "# print F1 scores of each\n",
    "print(classification_report(y_test, predictions_rf))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GBD For text classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7985611510791367\n",
      "F1 Score: 0.7529966485964479\n",
      "Confusion Matrix:\n",
      "[[  0   6  48]\n",
      " [  2  58  98]\n",
      " [  2  12 608]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Average       0.00      0.00      0.00        54\n",
      "         Bad       0.76      0.37      0.50       158\n",
      "        Good       0.81      0.98      0.88       622\n",
      "\n",
      "    accuracy                           0.80       834\n",
      "   macro avg       0.52      0.45      0.46       834\n",
      "weighted avg       0.75      0.80      0.75       834\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Initialize Gradient Boosting Classifier\n",
    "model_gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model_gb.fit(X_train_vectors, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions_gb = model_gb.predict(X_test_vectors)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_gb = accuracy_score(y_test, predictions_gb)\n",
    "print(\"Accuracy:\", accuracy_gb)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1_score_gb = f1_score(y_test, predictions_gb, average='weighted')\n",
    "print(\"F1 Score:\", f1_score_gb)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix_gb = confusion_matrix(y_test, predictions_gb)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_gb)\n",
    "\n",
    "# Classification report\n",
    "class_report_gb = classification_report(y_test, predictions_gb)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_gb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
